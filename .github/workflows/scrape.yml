name: Scrape + Deploy Pages (static, sem Jekyll)

on:
  schedule:
    - cron: "0 10,18 * * 1-5"
  workflow_dispatch: {}

permissions:
  pages: write
  id-token: write
  contents: read

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 20

      - run: npm ci

      - name: Rodar scraper
        env:
          FUNDAMENTUS_COOKIE: ${{ secrets.FUNDAMENTUS_COOKIE }}  # opcional
        run: node scrape.js

      - name: Garantir index + .nojekyll
        run: |
          mkdir -p docs
          [ -f docs/index.html ] || cat > docs/index.html <<'HTML'
          <meta charset="utf-8">
          <h1>fundamentus-proxy</h1>
          <ul>
            <li><a href="./resultado.html">resultado.html</a></li>
            <li><a href="./resultado.csv">resultado.csv</a></li>
          </ul>
          HTML
          touch docs/.nojekyll

      - name: Upload artifact (docs/)
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./docs

  deploy:
    runs-on: ubuntu-latest
    needs: build
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
